{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "imposed-fishing",
   "metadata": {},
   "source": [
    "# Script extracting example sentences from a corpus\n",
    "\n",
    "**Author**: Diane Marquette <br>\n",
    "**Date created**: 18/01/2021 <br>\n",
    "**Date last modified**: 22/01/2021 <br>\n",
    "**Python Version**: 3.8.5 <br>\n",
    "\n",
    "The goal of this script is to **extract example sentences from a French corpus**. \n",
    "\n",
    "We **focus on rare words that only appear 3 times** in the entire WordLex corpus. Example sentences are especially valuable for these words as they usually have a specific usage context. Plus, we won’t be overwhelmed by hundreds of potential example sentences.\n",
    "\n",
    "We use the French corpora from January 2012 provided by [HC Corpora](http://corpora.epizy.com/corpora.html). It comes with a \"Full Word List\" that includes all the words that exist in the corpus and how many times they appeared. \n",
    "\n",
    "Because this list of words is raw and includes a lot of \"garbage\", we double-check if the word exists in the [Lexique 383](http://www.lexique.org/shiny/openlexicon/) dataset.\n",
    "\n",
    "\n",
    "**Inputs**:\n",
    "- <code>french_corpus_2012_01_23</code> folder (from HC Corpora) including Fre_Blogs.txt, Fre_Newspapers.txt and Fre_Twitter.txt\n",
    "- <code>french_wordlist_full.txt</code> file (from HC Corpora) associated to the January 2012 corpus\n",
    "- <code>Lexique-query-2021-01-18 8-3-27.xlsx</code> file (downloaded from Lexique 383's website on January 18th, 2021), we only kept 4 columnes (word, \"lemme\", \"cgram\" and \"cgramortho\")\n",
    "\n",
    "**Output**:\n",
    "- CSV file with 3 columns ('Word', 'Language' and 'Example') containing example sentences for words appearing only 3 times in the original corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-lewis",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "We use the [sentence-splitter](https://pypi.org/project/sentence-splitter/) package to split the documents into sentences. It relies on a heuristic algorithm trained for different languages, including French, to split plain text into a list of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amber-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, codecs\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize \n",
    "from sentence_splitter import split_text_into_sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-track",
   "metadata": {},
   "source": [
    "## Import the list of words appearing in the HC Corpora corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "impressive-bracket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>µ</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>µa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>µalchimie</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>µallé</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>µbio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Frequency\n",
       "0          µ         16\n",
       "1         µa          1\n",
       "2  µalchimie          2\n",
       "3      µallé          1\n",
       "4       µbio          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = '/Users/dianemarquette/Documents/Master/Kamusi.nosync'\n",
    "file_WordLex = '/French_wordlist_full.txt'\n",
    "\n",
    "WordLex = pd.read_csv(data_folder+file_WordLex, sep='\\t', names=['Word', 'Frequency'])\n",
    "WordLex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ongoing-resident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574343, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordLex.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-asset",
   "metadata": {},
   "source": [
    "We only keep the words appearing 3 times in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "favorite-margin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>µg/l</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>µsd</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word  Frequency\n",
       "9   µg/l          3\n",
       "13   µsd          3\n",
       "28  0.02          3\n",
       "46  0.12          3\n",
       "48  0.13          3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_words = WordLex.loc[WordLex['Frequency']==3]\n",
    "rare_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "little-correlation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33129, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_words.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-soldier",
   "metadata": {},
   "source": [
    "Among the 574'343 words included in the list, only 33'129 words appear 3 times in the corpus from January 2012."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-latitude",
   "metadata": {},
   "source": [
    "## Import the list of words included in the Lexique 383 dataset  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-hampton",
   "metadata": {},
   "source": [
    "This list is much \"cleaner\" than the one from HC Corpora. We use the <code>openpyxl</code> package to read the .xlsx file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "naughty-sunglasses",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>lemme</th>\n",
       "      <th>cgram</th>\n",
       "      <th>cgramortho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NOM</td>\n",
       "      <td>NOM,AUX,VER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>avoir</td>\n",
       "      <td>AUX</td>\n",
       "      <td>NOM,AUX,VER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>avoir</td>\n",
       "      <td>VER</td>\n",
       "      <td>NOM,AUX,VER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a capella</td>\n",
       "      <td>a capella</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a cappella</td>\n",
       "      <td>a cappella</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word       lemme cgram   cgramortho\n",
       "0           a           a   NOM  NOM,AUX,VER\n",
       "1           a       avoir   AUX  NOM,AUX,VER\n",
       "2           a       avoir   VER  NOM,AUX,VER\n",
       "3   a capella   a capella   ADV          ADV\n",
       "4  a cappella  a cappella   ADV          ADV"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_lexique383 = '/Lexique-query-2021-01-18 8-3-27.xlsx'\n",
    "\n",
    "lexique383 = pd.read_excel(data_folder+file_lexique383, sheet_name='Sheet1', engine='openpyxl')\n",
    "lexique383.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "present-tuner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142694, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexique383.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-mexico",
   "metadata": {},
   "source": [
    "It \"only\" includes 142'694 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-filename",
   "metadata": {},
   "source": [
    "## Find words appearing three times in the corpus AND included in Lexique 383"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-louisiana",
   "metadata": {},
   "source": [
    "From the list of words appearing 3 times in the corpus, we only included those in the Lexique 383 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bibliographic-paragraph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>lemme</th>\n",
       "      <th>cgram</th>\n",
       "      <th>cgramortho</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandonnerez</td>\n",
       "      <td>abandonner</td>\n",
       "      <td>VER</td>\n",
       "      <td>VER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandonniez</td>\n",
       "      <td>abandonner</td>\n",
       "      <td>VER</td>\n",
       "      <td>VER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abattirent</td>\n",
       "      <td>abattre</td>\n",
       "      <td>VER</td>\n",
       "      <td>VER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abattis</td>\n",
       "      <td>abattis</td>\n",
       "      <td>NOM</td>\n",
       "      <td>NOM,VER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abattis</td>\n",
       "      <td>abattre</td>\n",
       "      <td>VER</td>\n",
       "      <td>NOM,VER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word       lemme cgram cgramortho  Frequency\n",
       "0  abandonnerez  abandonner   VER        VER          3\n",
       "1   abandonniez  abandonner   VER        VER          3\n",
       "2    abattirent     abattre   VER        VER          3\n",
       "3       abattis     abattis   NOM    NOM,VER          3\n",
       "4       abattis     abattre   VER    NOM,VER          3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words = pd.merge(lexique383, rare_words, on='Word', how='inner')\n",
    "common_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "affected-prospect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5810, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "mysterious-american",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique spellings: 5392\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique spellings: {}\".format(len(common_words.Word.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "satisfactory-bridal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique lemma: 4692\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique lemma: {}\".format(len(common_words.lemme.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-calvin",
   "metadata": {},
   "source": [
    "Only 5'810 words out of the 33'129 words occuring 3 times are also included in Lexique 383. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-canberra",
   "metadata": {},
   "source": [
    "## Import the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-assessment",
   "metadata": {},
   "source": [
    "We load the documents from each type of sources in a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "proof-gazette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Source Type</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nicematin.com</td>\n",
       "      <td>2011/10/11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17 heures à l'arrière du parc Phœnix, à Nice. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metrofrance.com</td>\n",
       "      <td>2011/04/07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Le chef de la diplomatie française, Alain Jupp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>leparisien.fr</td>\n",
       "      <td>2011/11/27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Depuis, la situation s’est améliorée… à Arago,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ledauphine.com</td>\n",
       "      <td>2011/04/11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Noël Duchêne et Patrice Vaniscotte ont fait le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ladepeche.fr</td>\n",
       "      <td>2012/01/11</td>\n",
       "      <td>1</td>\n",
       "      <td>4,12</td>\n",
       "      <td>C'est l'entreprise familiale Souyris de Carmau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Source Publication date Source Type Topics  \\\n",
       "0    nicematin.com       2011/10/11           1      0   \n",
       "1  metrofrance.com       2011/04/07           1      0   \n",
       "2    leparisien.fr       2011/11/27           1      0   \n",
       "3   ledauphine.com       2011/04/11           1      0   \n",
       "4     ladepeche.fr       2012/01/11           1   4,12   \n",
       "\n",
       "                                                Text  \n",
       "0  17 heures à l'arrière du parc Phœnix, à Nice. ...  \n",
       "1  Le chef de la diplomatie française, Alain Jupp...  \n",
       "2  Depuis, la situation s’est améliorée… à Arago,...  \n",
       "3  Noël Duchêne et Patrice Vaniscotte ont fait le...  \n",
       "4  C'est l'entreprise familiale Souyris de Carmau...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_root = data_folder+'/french_corpus_2012_01_23'\n",
    "corpus_files = ['/Fre_Newspapers.txt', '/Fre_Blogs.txt', '/Fre_Twitter.txt']\n",
    "\n",
    "column_names = ['Source', 'Publication date', 'Source Type', 'Topics', 'Text']\n",
    "corpus = pd.DataFrame(columns = column_names)\n",
    "\n",
    "# create dataframe with corpus docs\n",
    "for file in corpus_files:\n",
    "    content = pd.read_csv(corpus_root+file, sep='\\t', names=column_names)\n",
    "    corpus = pd.concat([corpus, content], ignore_index=True)\n",
    "\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-diversity",
   "metadata": {},
   "source": [
    "## Extract example sentences from corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "administrative-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize a document\n",
    "def tokenize(text):\n",
    "    text = \"\".join([ch for ch in text if ch not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "missing-oxford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No document including the word abandonnerez has been found.\n",
      "\n",
      "CPU times: user 23.6 s, sys: 117 ms, total: 23.7 s\n",
      "Wall time: 23.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = {}\n",
    "# counter to keep track of how many example sentences we found\n",
    "i=0\n",
    "\n",
    "# we only look for example sentences for the first 10 words of the dataframe\n",
    "# as a proof of concept (we ran this cell for all the words in the df using Google Colab)\n",
    "for word in common_words.Word.unique()[0:10]:\n",
    "    # retrieve documents (i.e., rows) from the corpus including this word\n",
    "    example_docs = corpus[corpus['Text'].str.contains(word, na=False, case=False)]\n",
    "    if example_docs.shape[0] == 0:\n",
    "        print(\"No document including the word {} has been found.\\n\".format(word))\n",
    "    else:\n",
    "        for index, row in example_docs.iterrows():\n",
    "            # check that the document really includes the word (e.g., 'beau') \n",
    "            # and not a string containing this word (e.g., 'beauté')\n",
    "            if word.lower() in word_tokenize(row['Text'].lower()):\n",
    "                try:\n",
    "                    text = split_text_into_sentences(text=row['Text'],language='fr')\n",
    "                    for sent in text:\n",
    "                        if word in sent:\n",
    "                            # add sentence including the word we're looking at as a key\n",
    "                            i += 1\n",
    "                            data[i] = [word, 'FRA', sent]\n",
    "                except:\n",
    "                    print(\"Something went wrong when splitting the text into sentences.\")\n",
    "\n",
    "\n",
    "# convert dictionary into a pandas dataframe\n",
    "example_sentences = pd.DataFrame.from_dict(data, orient='index', columns=['Word', 'Language', 'Example'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "experienced-passing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Language</th>\n",
       "      <th>Example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandonniez</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Si vous maintenez cette pratique sans faille d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abattirent</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Mais des hommes sont venus, qui firent avec ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abattirent</td>\n",
       "      <td>FRA</td>\n",
       "      <td>A ce spectacle, les chevaliers indignés se ruè...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abattirent</td>\n",
       "      <td>FRA</td>\n",
       "      <td>« Lui et ses compagnons abattirent une infinit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abattis</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Mohamed VI... numérotez vos abattis... votre h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abattis</td>\n",
       "      <td>FRA</td>\n",
       "      <td>J’abattis mon filet à papillon sur..le potiron.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abattis</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Numérotez vos abattis messieurs de la mafia, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abattis</td>\n",
       "      <td>FRA</td>\n",
       "      <td>C’était la première fois que je cuisinais une ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abattis</td>\n",
       "      <td>FRA</td>\n",
       "      <td>J’abattis mon filet à papillon sur..le potiron.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abattront</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Ce sont des INDIVIDUS visant un même objectif,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>abattront</td>\n",
       "      <td>FRA</td>\n",
       "      <td>colère et son courroux s’abattront sur lui et ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>abattront</td>\n",
       "      <td>FRA</td>\n",
       "      <td>L’Amérique n’entendait en effet, en vue des gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>abbesse</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Pour éviter que l’échiquier n’échoit aux Révol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aber</td>\n",
       "      <td>FRA</td>\n",
       "      <td>“….als ich….im Schaufenster der Buchhandlung ”...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aber</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Reviens sur mes propos sur les mec de aber, j'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>abhorrer</td>\n",
       "      <td>FRA</td>\n",
       "      <td>C’est là ce qui arrive à tous ceux qui, ne pén...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>abhorrer</td>\n",
       "      <td>FRA</td>\n",
       "      <td>J'aime bien le verbe abhorrer aussi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>abjectes</td>\n",
       "      <td>FRA</td>\n",
       "      <td>A une journaliste qui l'interrogeait sur le ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>abjectes</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Dans un communiqué, il a fait part de sa \"colè...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>abjectes</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Ses Dons pleuvaient; mais l’ingratitude et la ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>abjectes</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Puissiez vous, loin des abjectes précarités qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>abjectes</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Mgr Pavy, évêque d’Alger, déclarait en 1853 :«...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>abjectes</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Certaines scènes sont carrément abjectes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>abjectes</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Copé et ses conventions UMP où volent les prop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>abjectes</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Ces assassins entreront dans l’histoire pour l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>abjectes</td>\n",
       "      <td>FRA</td>\n",
       "      <td>personne dont les pensées et les réflexions so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>abjectes</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Disons qu'il y a deux adolescents laissés à eu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>abjectes</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Il est inadmissible et illégal qu’en Ile de Fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word Language                                            Example\n",
       "1   abandonniez      FRA  Si vous maintenez cette pratique sans faille d...\n",
       "2    abattirent      FRA  Mais des hommes sont venus, qui firent avec ce...\n",
       "3    abattirent      FRA  A ce spectacle, les chevaliers indignés se ruè...\n",
       "4    abattirent      FRA  « Lui et ses compagnons abattirent une infinit...\n",
       "5       abattis      FRA  Mohamed VI... numérotez vos abattis... votre h...\n",
       "6       abattis      FRA    J’abattis mon filet à papillon sur..le potiron.\n",
       "7       abattis      FRA  Numérotez vos abattis messieurs de la mafia, l...\n",
       "8       abattis      FRA  C’était la première fois que je cuisinais une ...\n",
       "9       abattis      FRA    J’abattis mon filet à papillon sur..le potiron.\n",
       "10    abattront      FRA  Ce sont des INDIVIDUS visant un même objectif,...\n",
       "11    abattront      FRA  colère et son courroux s’abattront sur lui et ...\n",
       "12    abattront      FRA  L’Amérique n’entendait en effet, en vue des gu...\n",
       "13      abbesse      FRA  Pour éviter que l’échiquier n’échoit aux Révol...\n",
       "14         aber      FRA  “….als ich….im Schaufenster der Buchhandlung ”...\n",
       "15         aber      FRA  Reviens sur mes propos sur les mec de aber, j'...\n",
       "16     abhorrer      FRA  C’est là ce qui arrive à tous ceux qui, ne pén...\n",
       "17     abhorrer      FRA               J'aime bien le verbe abhorrer aussi.\n",
       "18     abjectes      FRA  A une journaliste qui l'interrogeait sur le ca...\n",
       "19     abjectes      FRA  Dans un communiqué, il a fait part de sa \"colè...\n",
       "20     abjectes      FRA  Ses Dons pleuvaient; mais l’ingratitude et la ...\n",
       "21     abjectes      FRA  Puissiez vous, loin des abjectes précarités qu...\n",
       "22     abjectes      FRA  Mgr Pavy, évêque d’Alger, déclarait en 1853 :«...\n",
       "23     abjectes      FRA          Certaines scènes sont carrément abjectes.\n",
       "24     abjectes      FRA  Copé et ses conventions UMP où volent les prop...\n",
       "25     abjectes      FRA  Ces assassins entreront dans l’histoire pour l...\n",
       "26     abjectes      FRA  personne dont les pensées et les réflexions so...\n",
       "27     abjectes      FRA  Disons qu'il y a deux adolescents laissés à eu...\n",
       "28     abjectes      FRA  Il est inadmissible et illégal qu’en Ile de Fr..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accepted-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export dataframe as a CSV file\n",
    "\n",
    "example_sentences.to_csv(path_or_buf=data_folder+'/example_sentences.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-chile",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kamusi2",
   "language": "python",
   "name": "kamusi2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
