{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4j8EqbUgbRb"
   },
   "source": [
    "# Script extracting example sentences from a corpus\n",
    "\n",
    "**Author**: Diane Marquette <br>\n",
    "**Date created**: 18/01/2021 <br>\n",
    "**Date last modified**: 22/01/2021 <br>\n",
    "**Python Version**: 3.8.5 <br>\n",
    "\n",
    "**Note**: This script has been adapted to run on **Google Colab**. This avoids us to run locally the sentence extraction cell that took more than 6 hours to execute.\n",
    "\n",
    "The goal of this script is to **extract example sentences from a French corpus**. \n",
    "\n",
    "We **focus on rare words that only appear 3 times** in the entire WordLex corpus. Example sentences are especially valuable for these words as they usually have a specific usage context. Plus, we don't overwhelmed by hundreds of potential example sentences.\n",
    "\n",
    "We use the French corpora from January 2012 provided by [HC Corpora](http://corpora.epizy.com/corpora.html). It comes with a \"Full Word List\" that includes all the words that exist in the corpus and how many times they appeared. \n",
    "\n",
    "Because this list of words is raw and includes a lot of \"garbage\", we double-check if the word exists in the [Lexique 383](http://www.lexique.org/shiny/openlexicon/) dataset.\n",
    "\n",
    "\n",
    "**Inputs**:\n",
    "- <code>french_corpus_2012_01_23</code> folder (from HC Corpora) including <code>Fre_Blogs.txt</code>, <code>Fre_Newspapers.txt</code> and <code>Fre_Twitter.txt</code>\n",
    "- <code>french_wordlist_full.txt</code> file (from HC Corpora) associated to the January 2012 corpus\n",
    "- <code>Lexique-query-2021-01-18 8-3-27.xlsx</code> file (downloaded from Lexique 383's website on January 18th, 2021), we only kept 4 columns (\"word\", \"lemme\", \"cgram\" and \"cgramortho\")\n",
    "\n",
    "**Output**:\n",
    "- CSV file with 3 columns ('Word', 'Language' and 'Example') containing example sentences for words appearing only 3 times in the original corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qj8HoDP4gbRd"
   },
   "source": [
    "## Import libraries\n",
    "\n",
    "We use the [sentence-splitter](https://pypi.org/project/sentence-splitter/) package to split the documents into sentences. It relies on a heuristic algorithm trained for different languages, including French, to split plain text into a list of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rECFC8qgoom",
    "outputId": "e8d4938d-95e1-403c-82b0-70bcb08023ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_splitter in /usr/local/lib/python3.6/dist-packages (1.4)\n",
      "Requirement already satisfied: regex>=2017.12.12 in /usr/local/lib/python3.6/dist-packages (from sentence_splitter) (2019.12.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7kaeepBzgbRd"
   },
   "outputs": [],
   "source": [
    "import io, os, codecs\n",
    "import pandas as pd\n",
    "import nltk \n",
    "from sentence_splitter import split_text_into_sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7hyloYBAA8G"
   },
   "source": [
    "We mount our Drive to the Colab VM to later export there the generated CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ecdNn0Zb5Myn",
    "outputId": "797150d1-be0f-4169-e9e7-715623ce1ce0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount your Drive to the Colab VM.\n",
    "drive.mount('/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJbHPO-7AZ69"
   },
   "source": [
    "We upload all five files used in this script to the Colab VM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "qtRYDexaiaXp",
    "outputId": "a607f14c-a9ed-4a2b-9286-57224310e835"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-9ed8a3ab-39c3-402f-b0c6-af69a14b650f\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-9ed8a3ab-39c3-402f-b0c6-af69a14b650f\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Fre_Blogs.txt to Fre_Blogs (2).txt\n",
      "Saving Fre_Newspapers.txt to Fre_Newspapers (1).txt\n",
      "Saving Fre_Twitter.txt to Fre_Twitter (1).txt\n",
      "Saving french_wordlist_full.txt to french_wordlist_full (1).txt\n",
      "Saving Lexique-query-2021-01-18 8-3-27.xlsx to Lexique-query-2021-01-18 8-3-27 (1).xlsx\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ir9-qwTugbRe"
   },
   "source": [
    "## Import the list of words appearing in the HC Corpora corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "gVGXD22ugbRe",
    "outputId": "19789ba5-0970-429f-ce8d-5eda057ed4c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>µ</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>µa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>µalchimie</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>µallé</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>µbio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Frequency\n",
       "0          µ         16\n",
       "1         µa          1\n",
       "2  µalchimie          2\n",
       "3      µallé          1\n",
       "4       µbio          1"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_WordLex = 'french_wordlist_full.txt'\n",
    "\n",
    "WordLex = pd.read_csv(io.BytesIO(uploaded[file_WordLex]), \n",
    "                      sep='\\t', names=['Word', 'Frequency'])\n",
    "WordLex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XjuFwM48gbRe",
    "outputId": "e4c4a4b0-ea8b-4abd-b6b8-76125109dbe5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574343, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordLex.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27ulNqg9gbRf"
   },
   "source": [
    "We only keep the words appearing 3 times in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "TUtmSy00gbRf",
    "outputId": "7302ce6e-4d99-4ff6-f4c1-f0738e787346"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>µg/l</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>µsd</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word  Frequency\n",
       "9   µg/l          3\n",
       "13   µsd          3\n",
       "28  0.02          3\n",
       "46  0.12          3\n",
       "48  0.13          3"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_words = WordLex.loc[WordLex['Frequency']==3]\n",
    "rare_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdWIcPuAgbRf",
    "outputId": "7dfd30a0-4f7a-400c-c47b-89c1b187210b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33129, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_words.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWst2qWHgbRg"
   },
   "source": [
    "Among the 574'343 words included in the list, only 33'129 words appear 3 times in the corpus from January 2012."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJlsn_n8gbRg"
   },
   "source": [
    "## Import the list of words included in the Lexique 383 dataset  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3V1Th0wgbRg"
   },
   "source": [
    "This list is much \"cleaner\" than the one from HC Corpora. We use the <code>openpyxl</code> package to read the .xlsx file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "JnU9dKoOgbRg",
    "outputId": "41b2aca9-226c-418d-b6de-b5b906ea9957"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>lemme</th>\n",
       "      <th>cgram</th>\n",
       "      <th>cgramortho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NOM</td>\n",
       "      <td>NOM,AUX,VER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>avoir</td>\n",
       "      <td>AUX</td>\n",
       "      <td>NOM,AUX,VER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>avoir</td>\n",
       "      <td>VER</td>\n",
       "      <td>NOM,AUX,VER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a capella</td>\n",
       "      <td>a capella</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a cappella</td>\n",
       "      <td>a cappella</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word       lemme cgram   cgramortho\n",
       "0           a           a   NOM  NOM,AUX,VER\n",
       "1           a       avoir   AUX  NOM,AUX,VER\n",
       "2           a       avoir   VER  NOM,AUX,VER\n",
       "3   a capella   a capella   ADV          ADV\n",
       "4  a cappella  a cappella   ADV          ADV"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_lexique383 = 'Lexique-query-2021-01-18 8-3-27.xlsx'\n",
    "\n",
    "lexique383 = pd.read_excel(io.BytesIO(uploaded[file_lexique383]), sheet_name='Sheet1', engine='openpyxl')\n",
    "lexique383.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2uImr9FRgbRg",
    "outputId": "c66d7ec4-3d72-49ce-a995-154e52c6236f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142694, 4)"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexique383.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8CquD5xgbRg"
   },
   "source": [
    "It \"only\" includes 142'694 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LV75gvODgbRh"
   },
   "source": [
    "## Find words appearing three times in the corpus AND included in Lexique 383"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNf9zn-ogbRh"
   },
   "source": [
    "From the list of words appearing 3 times in the corpus, we only included those in the Lexique 383 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Qa_9C_eqgbRi",
    "outputId": "8ecf269c-417c-4a10-e64f-0bd1811e6596"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>lemme</th>\n",
       "      <th>cgram</th>\n",
       "      <th>cgramortho</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandonnerez</td>\n",
       "      <td>abandonner</td>\n",
       "      <td>VER</td>\n",
       "      <td>VER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandonniez</td>\n",
       "      <td>abandonner</td>\n",
       "      <td>VER</td>\n",
       "      <td>VER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abattirent</td>\n",
       "      <td>abattre</td>\n",
       "      <td>VER</td>\n",
       "      <td>VER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abattis</td>\n",
       "      <td>abattis</td>\n",
       "      <td>NOM</td>\n",
       "      <td>NOM,VER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abattis</td>\n",
       "      <td>abattre</td>\n",
       "      <td>VER</td>\n",
       "      <td>NOM,VER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word       lemme cgram cgramortho  Frequency\n",
       "0  abandonnerez  abandonner   VER        VER          3\n",
       "1   abandonniez  abandonner   VER        VER          3\n",
       "2    abattirent     abattre   VER        VER          3\n",
       "3       abattis     abattis   NOM    NOM,VER          3\n",
       "4       abattis     abattre   VER    NOM,VER          3"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words = pd.merge(lexique383, rare_words, on='Word', how='inner')\n",
    "common_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tUcE-cWmgbRi",
    "outputId": "c5b5d947-501d-4e2e-9bc4-4bd8ce3782f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5810, 5)"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xedcJce2gbRi",
    "outputId": "a959d636-9f47-4163-8839-b1366a496f31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique spellings: 5392\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique spellings: {}\".format(len(common_words.Word.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SCpvMW6LgbRi",
    "outputId": "c85989dd-2b73-4f62-8ded-41b820bb3b50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique lemma: 4692\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique lemma: {}\".format(len(common_words.lemme.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWfHl4E2gbRi"
   },
   "source": [
    "Only 5'810 words out of the 33'129 words occuring 3 times are also included in Lexique 383. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36uNnPMugbRi"
   },
   "source": [
    "## Import the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOVo6hkMgbRi"
   },
   "source": [
    "We load the documents from each type of sources in a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "K4IE5Tm-gbRi",
    "outputId": "9f65c877-2fe0-40fe-8a91-62338a4ffe86"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Source Type</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nicematin.com</td>\n",
       "      <td>2011/10/11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17 heures à l'arrière du parc Phœnix, à Nice. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metrofrance.com</td>\n",
       "      <td>2011/04/07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Le chef de la diplomatie française, Alain Jupp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>leparisien.fr</td>\n",
       "      <td>2011/11/27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Depuis, la situation s’est améliorée… à Arago,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ledauphine.com</td>\n",
       "      <td>2011/04/11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Noël Duchêne et Patrice Vaniscotte ont fait le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ladepeche.fr</td>\n",
       "      <td>2012/01/11</td>\n",
       "      <td>1</td>\n",
       "      <td>4,12</td>\n",
       "      <td>C'est l'entreprise familiale Souyris de Carmau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Source  ...                                               Text\n",
       "0    nicematin.com  ...  17 heures à l'arrière du parc Phœnix, à Nice. ...\n",
       "1  metrofrance.com  ...  Le chef de la diplomatie française, Alain Jupp...\n",
       "2    leparisien.fr  ...  Depuis, la situation s’est améliorée… à Arago,...\n",
       "3   ledauphine.com  ...  Noël Duchêne et Patrice Vaniscotte ont fait le...\n",
       "4     ladepeche.fr  ...  C'est l'entreprise familiale Souyris de Carmau...\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_files = ['Fre_Newspapers.txt', 'Fre_Blogs.txt', 'Fre_Twitter.txt']\n",
    "\n",
    "column_names = ['Source', 'Publication date', 'Source Type', 'Topics', 'Text']\n",
    "corpus = pd.DataFrame(columns = column_names)\n",
    "\n",
    "# create dataframe with corpus docs\n",
    "for file in corpus_files:\n",
    "    content = pd.read_csv(io.BytesIO(uploaded[file]), sep='\\t', names=column_names)\n",
    "    corpus = pd.concat([corpus, content], ignore_index=True)\n",
    "\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2swLayygbRj"
   },
   "source": [
    "## Extract example sentences from corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXs6P4KIgbRj"
   },
   "outputs": [],
   "source": [
    "# Tokenize a document\n",
    "def tokenize(text):\n",
    "    text = \"\".join([ch for ch in text if ch not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwG31GvRgbRj",
    "outputId": "3bd981b4-103e-4d6f-fbe8-f32362726c98",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No document including the word abandonnerez has been found.\n",
      "\n",
      "No document including the word abusèrent has been found.\n",
      "\n",
      "No document including the word accélérais has been found.\n",
      "\n",
      "No document including the word adresserez has been found.\n",
      "\n",
      "No document including the word agençait has been found.\n",
      "\n",
      "No document including the word alanguissait has been found.\n",
      "\n",
      "No document including the word alchimies has been found.\n",
      "\n",
      "No document including the word amphigouriques has been found.\n",
      "\n",
      "No document including the word américaniser has been found.\n",
      "\n",
      "No document including the word anabase has been found.\n",
      "\n",
      "No document including the word androgynie has been found.\n",
      "\n",
      "No document including the word angéliquement has been found.\n",
      "\n",
      "No document including the word annihilent has been found.\n",
      "\n",
      "No document including the word anoxie has been found.\n",
      "\n",
      "No document including the word anti-castristes has been found.\n",
      "\n",
      "No document including the word anti-patriotique has been found.\n",
      "\n",
      "No document including the word anti-reflets has been found.\n",
      "\n",
      "No document including the word anti-sociaux has been found.\n",
      "\n",
      "No document including the word antigrippe has been found.\n",
      "\n",
      "No document including the word antisolaires has been found.\n",
      "\n",
      "No document including the word applaudiraient has been found.\n",
      "\n",
      "No document including the word approfondirons has been found.\n",
      "\n",
      "No document including the word apprécierions has been found.\n",
      "\n",
      "No document including the word apprécièrent has been found.\n",
      "\n",
      "No document including the word arborescentes has been found.\n",
      "\n",
      "No document including the word argilière has been found.\n",
      "\n",
      "No document including the word arrêteriez has been found.\n",
      "\n",
      "No document including the word aspergeaient has been found.\n",
      "\n",
      "No document including the word aspergeait has been found.\n",
      "\n",
      "No document including the word asticoter has been found.\n",
      "\n",
      "No document including the word asymptomatiques has been found.\n",
      "\n",
      "No document including the word atteignions has been found.\n",
      "\n",
      "No document including the word attroupent has been found.\n",
      "\n",
      "No document including the word aumônières has been found.\n",
      "\n",
      "No document including the word avéreraient has been found.\n",
      "\n",
      "No document including the word axels has been found.\n",
      "\n",
      "No document including the word aérage has been found.\n",
      "\n",
      "No document including the word balloches has been found.\n",
      "\n",
      "No document including the word balluchons has been found.\n",
      "\n",
      "No document including the word baptises has been found.\n",
      "\n",
      "No document including the word baryum has been found.\n",
      "\n",
      "No document including the word behavioriste has been found.\n",
      "\n",
      "No document including the word bercements has been found.\n",
      "\n",
      "No document including the word binoclarde has been found.\n",
      "\n",
      "No document including the word bistroquet has been found.\n",
      "\n",
      "No document including the word bistrotières has been found.\n",
      "\n",
      "No document including the word bizuts has been found.\n",
      "\n",
      "No document including the word blancs-becs has been found.\n",
      "\n",
      "No document including the word blesserait has been found.\n",
      "\n",
      "No document including the word bleu-noir has been found.\n",
      "\n",
      "No document including the word bottez has been found.\n",
      "\n",
      "No document including the word boutres has been found.\n",
      "\n",
      "No document including the word brachiosaure has been found.\n",
      "\n",
      "No document including the word bradycardie has been found.\n",
      "\n",
      "No document including the word brimées has been found.\n",
      "\n",
      "No document including the word brugnons has been found.\n",
      "\n",
      "No document including the word bushman has been found.\n",
      "\n",
      "No document including the word béguins has been found.\n",
      "\n",
      "No document including the word bésicles has been found.\n",
      "\n",
      "No document including the word bêlait has been found.\n",
      "\n",
      "No document including the word calligraphier has been found.\n",
      "\n",
      "No document including the word calorifères has been found.\n",
      "\n",
      "No document including the word cambrer has been found.\n",
      "\n",
      "No document including the word casserez has been found.\n",
      "\n",
      "No document including the word cataloguent has been found.\n",
      "\n",
      "No document including the word chagrinés has been found.\n",
      "\n",
      "No document including the word chasseraient has been found.\n",
      "\n",
      "No document including the word chassions has been found.\n",
      "\n",
      "No document including the word chavirée has been found.\n",
      "\n",
      "No document including the word chenillettes has been found.\n",
      "\n",
      "No document including the word chipoté has been found.\n",
      "\n",
      "No document including the word choyait has been found.\n",
      "\n",
      "No document including the word chthoniennes has been found.\n",
      "\n",
      "No document including the word chétives has been found.\n",
      "\n",
      "No document including the word cimentés has been found.\n",
      "\n",
      "No document including the word cloisonnements has been found.\n",
      "\n",
      "No document including the word clopinant has been found.\n",
      "\n",
      "No document including the word cocagnes has been found.\n",
      "\n",
      "No document including the word cokes has been found.\n",
      "\n",
      "No document including the word collectivisés has been found.\n",
      "\n",
      "No document including the word commensaux has been found.\n",
      "\n",
      "No document including the word communiait has been found.\n",
      "\n",
      "No document including the word comparaissant has been found.\n",
      "\n",
      "No document including the word compromets has been found.\n",
      "\n",
      "No document including the word condescendre has been found.\n",
      "\n",
      "No document including the word conquerront has been found.\n",
      "\n",
      "No document including the word consciencieuses has been found.\n",
      "\n",
      "No document including the word consolateurs has been found.\n",
      "\n",
      "No document including the word conspiraient has been found.\n",
      "\n",
      "No document including the word consulterons has been found.\n",
      "\n",
      "No document including the word contraignit has been found.\n",
      "\n",
      "No document including the word contrasterait has been found.\n",
      "\n",
      "No document including the word contre-terroriste has been found.\n",
      "\n",
      "No document including the word contremarques has been found.\n",
      "\n",
      "No document including the word convertissaient has been found.\n",
      "\n",
      "No document including the word convulser has been found.\n",
      "\n",
      "No document including the word coproducteurs has been found.\n",
      "\n",
      "No document including the word cordelle has been found.\n",
      "\n",
      "No document including the word cornaquée has been found.\n",
      "\n",
      "No document including the word cornélienne has been found.\n",
      "\n",
      "No document including the word corrigerez has been found.\n",
      "\n",
      "No document including the word couleras has been found.\n",
      "\n",
      "No document including the word couplages has been found.\n",
      "\n",
      "No document including the word courtages has been found.\n",
      "\n",
      "No document including the word coïncidèrent has been found.\n",
      "\n",
      "No document including the word crataegus has been found.\n",
      "\n",
      "No document including the word crossé has been found.\n",
      "\n",
      "No document including the word crèverons has been found.\n",
      "\n",
      "No document including the word crémés has been found.\n",
      "\n",
      "No document including the word cuisaient has been found.\n",
      "\n",
      "No document including the word culpabilisait has been found.\n",
      "\n",
      "No document including the word dahus has been found.\n",
      "\n",
      "No document including the word dartres has been found.\n",
      "\n",
      "No document including the word dessoudé has been found.\n",
      "\n",
      "No document including the word dialoguistes has been found.\n",
      "\n",
      "No document including the word diamantine has been found.\n",
      "\n",
      "No document including the word diaprée has been found.\n",
      "\n",
      "No document including the word diatomées has been found.\n",
      "\n",
      "No document including the word dictais has been found.\n",
      "\n",
      "No document including the word diminuèrent has been found.\n",
      "\n",
      "No document including the word discernant has been found.\n",
      "\n",
      "No document including the word disposiez has been found.\n",
      "\n",
      "No document including the word dissolvaient has been found.\n",
      "\n",
      "No document including the word distension has been found.\n",
      "\n",
      "No document including the word dreyfusards has been found.\n",
      "\n",
      "No document including the word dribblait has been found.\n",
      "\n",
      "No document including the word dropent has been found.\n",
      "\n",
      "No document including the word durcissait has been found.\n",
      "\n",
      "No document including the word durèrent has been found.\n",
      "\n",
      "No document including the word débattraient has been found.\n",
      "\n",
      "No document including the word débitaient has been found.\n",
      "\n",
      "No document including the word déboutait has been found.\n",
      "\n",
      "No document including the word décacheter has been found.\n",
      "\n",
      "No document including the word décanteur has been found.\n",
      "\n",
      "No document including the word décapeur has been found.\n",
      "\n",
      "No document including the word décelait has been found.\n",
      "\n",
      "No document including the word décevrais has been found.\n",
      "\n",
      "No document including the word décriraient has been found.\n",
      "\n",
      "No document including the word décroiser has been found.\n",
      "\n",
      "No document including the word dédaigneuses has been found.\n",
      "\n",
      "No document including the word défrichait has been found.\n",
      "\n",
      "No document including the word dégorgés has been found.\n",
      "\n",
      "No document including the word dégotés has been found.\n",
      "\n",
      "No document including the word dégoulines has been found.\n",
      "\n",
      "No document including the word dégoûtez has been found.\n",
      "\n",
      "No document including the word délectes has been found.\n",
      "\n",
      "No document including the word démones has been found.\n",
      "\n",
      "No document including the word dépeceur has been found.\n",
      "\n",
      "No document including the word déposeras has been found.\n",
      "\n",
      "No document including the word dérangeons has been found.\n",
      "\n",
      "No document including the word déroutées has been found.\n",
      "\n",
      "No document including the word désacralisée has been found.\n",
      "\n",
      "No document including the word désalinisation has been found.\n",
      "\n",
      "No document including the word désaveux has been found.\n",
      "\n",
      "No document including the word désaxe has been found.\n",
      "\n",
      "No document including the word désenchanter has been found.\n",
      "\n",
      "No document including the word déshonnêtes has been found.\n",
      "\n",
      "No document including the word désillusionnement has been found.\n",
      "\n",
      "No document including the word désintégrés has been found.\n",
      "\n",
      "No document including the word désintéressaient has been found.\n",
      "\n",
      "No document including the word déstalinisation has been found.\n",
      "\n",
      "No document including the word déstocké has been found.\n",
      "\n",
      "No document including the word détendais has been found.\n",
      "\n",
      "No document including the word déterminerons has been found.\n",
      "\n",
      "No document including the word détourneraient has been found.\n",
      "\n",
      "No document including the word développerez has been found.\n",
      "\n",
      "No document including the word dévirilisation has been found.\n",
      "\n",
      "No document including the word dévorèrent has been found.\n",
      "\n",
      "No document including the word dévêtus has been found.\n",
      "\n",
      "No document including the word efflanqués has been found.\n",
      "\n",
      "No document including the word effondreraient has been found.\n",
      "\n",
      "No document including the word effrayez has been found.\n",
      "\n",
      "No document including the word emboutit has been found.\n",
      "\n",
      "No document including the word embrassions has been found.\n",
      "\n",
      "No document including the word embrouillant has been found.\n",
      "\n",
      "No document including the word embuait has been found.\n",
      "\n",
      "No document including the word embêtais has been found.\n",
      "\n",
      "No document including the word embêterais has been found.\n",
      "\n",
      "No document including the word emmanché has been found.\n",
      "\n",
      "No document including the word emmerdeuses has been found.\n",
      "\n",
      "No document including the word emmitouflait has been found.\n",
      "\n",
      "No document including the word empaffés has been found.\n",
      "\n",
      "No document including the word empiétait has been found.\n",
      "\n",
      "No document including the word enchaînais has been found.\n",
      "\n",
      "No document including the word encordés has been found.\n",
      "\n",
      "No document including the word endoscope has been found.\n",
      "\n",
      "No document including the word enfouissements has been found.\n",
      "\n",
      "No document including the word englobés has been found.\n",
      "\n",
      "No document including the word enivres has been found.\n",
      "\n",
      "No document including the word enkystées has been found.\n",
      "\n",
      "No document including the word enlaidissent has been found.\n",
      "\n",
      "No document including the word enroulaient has been found.\n",
      "\n",
      "No document including the word enseignèrent has been found.\n",
      "\n",
      "No document including the word ensorcelées has been found.\n",
      "\n",
      "No document including the word ensuivront has been found.\n",
      "\n",
      "No document including the word entamèrent has been found.\n",
      "\n",
      "No document including the word enterrerait has been found.\n",
      "\n",
      "No document including the word enthousiasmaient has been found.\n",
      "\n",
      "No document including the word entretuaient has been found.\n",
      "\n",
      "No document including the word entrevoyait has been found.\n",
      "\n",
      "No document including the word envenimés has been found.\n",
      "\n",
      "No document including the word environnaient has been found.\n",
      "\n",
      "No document including the word esclaffant has been found.\n",
      "\n",
      "No document including the word ex-batteur has been found.\n",
      "\n",
      "No document including the word exaspéraient has been found.\n",
      "\n",
      "No document including the word existèrent has been found.\n",
      "\n",
      "No document including the word expérimentaient has been found.\n",
      "\n",
      "No document including the word fanatiser has been found.\n",
      "\n",
      "No document including the word fanfaronnant has been found.\n",
      "\n",
      "No document including the word fauchait has been found.\n",
      "\n",
      "No document including the word façonnable has been found.\n",
      "\n",
      "No document including the word faîtière has been found.\n",
      "\n",
      "No document including the word fendants has been found.\n",
      "\n",
      "No document including the word festonnées has been found.\n",
      "\n",
      "No document including the word feuillantines has been found.\n",
      "\n",
      "No document including the word fiancent has been found.\n",
      "\n",
      "No document including the word figurativement has been found.\n",
      "\n",
      "No document including the word figurèrent has been found.\n",
      "\n",
      "No document including the word fixatif has been found.\n",
      "\n",
      "No document including the word flafla has been found.\n",
      "\n",
      "No document including the word flegmatisme has been found.\n",
      "\n",
      "No document including the word foehn has been found.\n",
      "\n",
      "No document including the word folioles has been found.\n",
      "\n",
      "No document including the word foreuses has been found.\n",
      "\n",
      "No document including the word forgeait has been found.\n",
      "\n",
      "No document including the word formulaient has been found.\n",
      "\n",
      "No document including the word fredaines has been found.\n",
      "\n",
      "No document including the word friabilité has been found.\n",
      "\n",
      "No document including the word friment has been found.\n",
      "\n",
      "No document including the word friquées has been found.\n",
      "\n",
      "No document including the word frisottants has been found.\n",
      "\n",
      "No document including the word frémissez has been found.\n",
      "\n",
      "No document including the word fréquentèrent has been found.\n",
      "\n",
      "No document including the word frétillements has been found.\n",
      "\n",
      "No document including the word funiculaires has been found.\n",
      "\n",
      "No document including the word ganses has been found.\n",
      "\n",
      "No document including the word gazinières has been found.\n",
      "\n",
      "No document including the word gibelin has been found.\n",
      "\n",
      "No document including the word giclent has been found.\n",
      "\n",
      "No document including the word giroflées has been found.\n",
      "\n",
      "No document including the word glacials has been found.\n",
      "\n",
      "No document including the word glaneuse has been found.\n",
      "\n",
      "No document including the word gloses has been found.\n",
      "\n",
      "No document including the word gobera has been found.\n",
      "\n",
      "No document including the word gobeurs has been found.\n",
      "\n",
      "No document including the word goinfrerie has been found.\n",
      "\n",
      "No document including the word goinfrés has been found.\n",
      "\n",
      "No document including the word goures has been found.\n",
      "\n",
      "No document including the word gourés has been found.\n",
      "\n",
      "No document including the word granuleuses has been found.\n",
      "\n",
      "No document including the word grils has been found.\n",
      "\n",
      "No document including the word grimpants has been found.\n",
      "\n",
      "No document including the word grisent has been found.\n",
      "\n",
      "No document including the word guillaumes has been found.\n",
      "\n",
      "No document including the word guimpe has been found.\n",
      "\n",
      "No document including the word guérets has been found.\n",
      "\n",
      "No document including the word gymnastiques has been found.\n",
      "\n",
      "No document including the word gâterait has been found.\n",
      "\n",
      "No document including the word gémissez has been found.\n",
      "\n",
      "No document including the word hacheur has been found.\n",
      "\n",
      "No document including the word haineusement has been found.\n",
      "\n",
      "No document including the word harassement has been found.\n",
      "\n",
      "No document including the word hargneusement has been found.\n",
      "\n",
      "No document including the word harponneur has been found.\n",
      "\n",
      "No document including the word hennit has been found.\n",
      "\n",
      "No document including the word homophonie has been found.\n",
      "\n",
      "No document including the word humanisées has been found.\n",
      "\n",
      "No document including the word hydrocéphalie has been found.\n",
      "\n",
      "No document including the word hypertrophiée has been found.\n",
      "\n",
      "No document including the word hypostase has been found.\n",
      "\n",
      "No document including the word ice-cream has been found.\n",
      "\n",
      "No document including the word idiotisme has been found.\n",
      "\n",
      "No document including the word idolâtries has been found.\n",
      "\n",
      "No document including the word imbibait has been found.\n",
      "\n",
      "No document including the word immunologique has been found.\n",
      "\n",
      "No document including the word impavides has been found.\n",
      "\n",
      "No document including the word imperméabiliser has been found.\n",
      "\n",
      "No document including the word impressionnées has been found.\n",
      "\n",
      "No document including the word impubères has been found.\n",
      "\n",
      "No document including the word incapacitants has been found.\n",
      "\n",
      "No document including the word incommodes has been found.\n",
      "\n",
      "No document including the word incontinences has been found.\n",
      "\n",
      "No document including the word inculquons has been found.\n",
      "\n",
      "No document including the word incurablement has been found.\n",
      "\n",
      "No document including the word incurver has been found.\n",
      "\n",
      "No document including the word incurvés has been found.\n",
      "\n",
      "No document including the word inexactement has been found.\n",
      "\n",
      "No document including the word infinitifs has been found.\n",
      "\n",
      "No document including the word influençaient has been found.\n",
      "\n",
      "No document including the word infusent has been found.\n",
      "\n",
      "No document including the word inoculation has been found.\n",
      "\n",
      "No document including the word inoculées has been found.\n",
      "\n",
      "No document including the word insistances has been found.\n",
      "\n",
      "No document including the word installâmes has been found.\n",
      "\n",
      "No document including the word instantes has been found.\n",
      "\n",
      "No document including the word instrumenter has been found.\n",
      "\n",
      "No document including the word intercostale has been found.\n",
      "\n",
      "No document including the word interdirent has been found.\n",
      "\n",
      "No document including the word interrompis has been found.\n",
      "\n",
      "No document including the word intersidéraux has been found.\n",
      "\n",
      "No document including the word inventeraient has been found.\n",
      "\n",
      "No document including the word inviolées has been found.\n",
      "\n",
      "No document including the word invoquais has been found.\n",
      "\n",
      "No document including the word irrésolues has been found.\n",
      "\n",
      "No document including the word isolements has been found.\n",
      "\n",
      "No document including the word italo-brésilien has been found.\n",
      "\n",
      "No document including the word jalonnaient has been found.\n",
      "\n",
      "No document including the word japonisants has been found.\n",
      "\n",
      "No document including the word javelliser has been found.\n",
      "\n",
      "No document including the word jeannettes has been found.\n",
      "\n",
      "No document including the word jouvencelles has been found.\n",
      "\n",
      "No document including the word lambswool has been found.\n",
      "\n",
      "No document including the word lasseront has been found.\n",
      "\n",
      "No document including the word lidocaïne has been found.\n",
      "\n",
      "No document including the word lilium has been found.\n",
      "\n",
      "No document including the word limonadier has been found.\n",
      "\n",
      "No document including the word lingam has been found.\n",
      "\n",
      "No document including the word liquidambars has been found.\n",
      "\n",
      "No document including the word liquiderait has been found.\n",
      "\n",
      "No document including the word liquidez has been found.\n",
      "\n",
      "No document including the word louvoiements has been found.\n",
      "\n",
      "No document including the word lâcheraient has been found.\n",
      "\n",
      "No document including the word malpropreté has been found.\n",
      "\n",
      "No document including the word manchote has been found.\n",
      "\n",
      "No document including the word mandrill has been found.\n",
      "\n",
      "No document including the word maniaquement has been found.\n",
      "\n",
      "No document including the word manigancent has been found.\n",
      "\n",
      "No document including the word manucurées has been found.\n",
      "\n",
      "No document including the word mappemondes has been found.\n",
      "\n",
      "No document including the word marcherions has been found.\n",
      "\n",
      "No document including the word marierons has been found.\n",
      "\n",
      "No document including the word masturbais has been found.\n",
      "\n",
      "No document including the word maudissait has been found.\n",
      "\n",
      "No document including the word mendiait has been found.\n",
      "\n",
      "No document including the word mentiras has been found.\n",
      "\n",
      "No document including the word mer-air has been found.\n",
      "\n",
      "No document including the word mi-carême has been found.\n",
      "\n",
      "No document including the word mi-sérieux has been found.\n",
      "\n",
      "No document including the word mictions has been found.\n",
      "\n",
      "No document including the word milites has been found.\n",
      "\n",
      "No document including the word mistoufles has been found.\n",
      "\n",
      "No document including the word mithridatisation has been found.\n",
      "\n",
      "No document including the word mitonnent has been found.\n",
      "\n",
      "No document including the word mitonnés has been found.\n",
      "\n",
      "No document including the word mobilisions has been found.\n",
      "\n",
      "No document including the word modificateur has been found.\n",
      "\n",
      "No document including the word mokas has been found.\n",
      "\n",
      "No document including the word molestation has been found.\n",
      "\n",
      "No document including the word monumentalement has been found.\n",
      "\n",
      "No document including the word moquèrent has been found.\n",
      "\n",
      "No document including the word mordraient has been found.\n",
      "\n",
      "No document including the word morfales has been found.\n",
      "\n",
      "No document including the word mortifiant has been found.\n",
      "\n",
      "No document including the word mortifier has been found.\n",
      "\n",
      "No document including the word mouds has been found.\n",
      "\n",
      "No document including the word mufles has been found.\n",
      "\n",
      "No document including the word muridés has been found.\n",
      "\n",
      "No document including the word méningiome has been found.\n",
      "\n",
      "No document including the word méningites has been found.\n",
      "\n",
      "No document including the word métamorphosèrent has been found.\n",
      "\n",
      "No document including the word narcose has been found.\n",
      "\n",
      "No document including the word narquoises has been found.\n",
      "\n",
      "No document including the word natter has been found.\n",
      "\n",
      "No document including the word nettoierait has been found.\n",
      "\n",
      "No document including the word neutraliste has been found.\n",
      "\n",
      "No document including the word neutropénie has been found.\n",
      "\n",
      "No document including the word nicaraguayens has been found.\n",
      "\n",
      "No document including the word niobium has been found.\n",
      "\n",
      "No document including the word nivellent has been found.\n",
      "\n",
      "No document including the word noierait has been found.\n",
      "\n",
      "No document including the word norias has been found.\n",
      "\n",
      "No document including the word nuiteux has been found.\n",
      "\n",
      "No document including the word nécrophiles has been found.\n",
      "\n",
      "No document including the word néo-fascisme has been found.\n",
      "\n",
      "No document including the word obligeriez has been found.\n",
      "\n",
      "No document including the word obstétricienne has been found.\n",
      "\n",
      "No document including the word officiais has been found.\n",
      "\n",
      "No document including the word onirologie has been found.\n",
      "\n",
      "No document including the word orangeraie has been found.\n",
      "\n",
      "No document including the word organon has been found.\n",
      "\n",
      "No document including the word outrageantes has been found.\n",
      "\n",
      "No document including the word pampres has been found.\n",
      "\n",
      "No document including the word panathénées has been found.\n",
      "\n",
      "No document including the word pantographes has been found.\n",
      "\n",
      "No document including the word papillonnait has been found.\n",
      "\n",
      "No document including the word papillonnement has been found.\n",
      "\n",
      "No document including the word paralogismes has been found.\n",
      "\n",
      "No document including the word parcheminés has been found.\n",
      "\n",
      "No document including the word parlerions has been found.\n",
      "\n",
      "No document including the word parqueteur has been found.\n",
      "\n",
      "No document including the word partageâmes has been found.\n",
      "\n",
      "No document including the word pasteurisation has been found.\n",
      "\n",
      "No document including the word pataudes has been found.\n",
      "\n",
      "No document including the word patrilinéaire has been found.\n",
      "\n",
      "No document including the word patronnesses has been found.\n",
      "\n",
      "No document including the word patronymique has been found.\n",
      "\n",
      "No document including the word peindrais has been found.\n",
      "\n",
      "No document including the word perquise has been found.\n",
      "\n",
      "No document including the word personnifiait has been found.\n",
      "\n",
      "No document including the word persévérait has been found.\n",
      "\n",
      "No document including the word pestilentiels has been found.\n",
      "\n",
      "No document including the word phallocratie has been found.\n",
      "\n",
      "No document including the word pharisaïsme has been found.\n",
      "\n",
      "No document including the word photogravure has been found.\n",
      "\n",
      "No document including the word photophobie has been found.\n",
      "\n",
      "No document including the word picaillons has been found.\n",
      "\n",
      "No document including the word pipe-lines has been found.\n",
      "\n",
      "No document including the word piètrement has been found.\n",
      "\n",
      "No document including the word plaises has been found.\n",
      "\n",
      "No document including the word planquerais has been found.\n",
      "\n",
      "No document including the word planétoïde has been found.\n",
      "\n",
      "No document including the word plombaient has been found.\n",
      "\n",
      "No document including the word plébiscites has been found.\n",
      "\n",
      "No document including the word pointèrent has been found.\n",
      "\n",
      "No document including the word polski has been found.\n",
      "\n",
      "No document including the word post-natale has been found.\n",
      "\n",
      "No document including the word postillonnant has been found.\n",
      "\n",
      "No document including the word potines has been found.\n",
      "\n",
      "No document including the word pouacre has been found.\n",
      "\n",
      "No document including the word prièrent has been found.\n",
      "\n",
      "No document including the word professaient has been found.\n",
      "\n",
      "No document including the word progresserons has been found.\n",
      "\n",
      "No document including the word projetèrent has been found.\n",
      "\n",
      "No document including the word prolapsus has been found.\n",
      "\n",
      "No document including the word prononciez has been found.\n",
      "\n",
      "No document including the word prouverons has been found.\n",
      "\n",
      "No document including the word prédisposées has been found.\n",
      "\n",
      "No document including the word présidaient has been found.\n",
      "\n",
      "No document including the word psalmodies has been found.\n",
      "\n",
      "No document including the word pâmoisons has been found.\n",
      "\n",
      "No document including the word pâtres has been found.\n",
      "\n",
      "No document including the word pénétrées has been found.\n",
      "\n",
      "No document including the word péroraisons has been found.\n",
      "\n",
      "No document including the word querellaient has been found.\n",
      "\n",
      "No document including the word quintettes has been found.\n",
      "\n",
      "No document including the word rabouter has been found.\n",
      "\n",
      "No document including the word rabâchait has been found.\n",
      "\n",
      "No document including the word raccrochons has been found.\n",
      "\n",
      "No document including the word raisiné has been found.\n",
      "\n",
      "No document including the word rajeunies has been found.\n",
      "\n",
      "No document including the word rallumant has been found.\n",
      "\n",
      "No document including the word ramenions has been found.\n",
      "\n",
      "No document including the word ramèneraient has been found.\n",
      "\n",
      "No document including the word rassasient has been found.\n",
      "\n",
      "No document including the word raturées has been found.\n",
      "\n",
      "No document including the word rebellant has been found.\n",
      "\n",
      "No document including the word rebutantes has been found.\n",
      "\n",
      "No document including the word rechercheront has been found.\n",
      "\n",
      "No document including the word recombinant has been found.\n",
      "\n",
      "No document including the word recombiner has been found.\n",
      "\n",
      "No document including the word recommencèrent has been found.\n",
      "\n",
      "No document including the word reconsidèrent has been found.\n",
      "\n",
      "No document including the word reconstruisait has been found.\n",
      "\n",
      "No document including the word reconvoquer has been found.\n",
      "\n",
      "No document including the word recopiez has been found.\n",
      "\n",
      "No document including the word redescendais has been found.\n",
      "\n",
      "No document including the word redonnerons has been found.\n",
      "\n",
      "No document including the word redoublons has been found.\n",
      "\n",
      "No document including the word regagnais has been found.\n",
      "\n",
      "No document including the word relevailles has been found.\n",
      "\n",
      "No document including the word releveurs has been found.\n",
      "\n",
      "No document including the word relirez has been found.\n",
      "\n",
      "No document including the word relâchaient has been found.\n",
      "\n",
      "No document including the word remballés has been found.\n",
      "\n",
      "No document including the word remorqueuse has been found.\n",
      "\n",
      "No document including the word remuscler has been found.\n",
      "\n",
      "No document including the word remués has been found.\n",
      "\n",
      "No document including the word rencogna has been found.\n",
      "\n",
      "No document including the word reniflait has been found.\n",
      "\n",
      "No document including the word rentrerions has been found.\n",
      "\n",
      "No document including the word renverrons has been found.\n",
      "\n",
      "No document including the word reparlais has been found.\n",
      "\n",
      "No document including the word replongeais has been found.\n",
      "\n",
      "No document including the word reposais has been found.\n",
      "\n",
      "No document including the word reposerais has been found.\n",
      "\n",
      "No document including the word repousseront has been found.\n",
      "\n",
      "No document including the word repérerait has been found.\n",
      "\n",
      "No document including the word respecterez has been found.\n",
      "\n",
      "No document including the word resserrage has been found.\n",
      "\n",
      "No document including the word ressortiraient has been found.\n",
      "\n",
      "No document including the word restituait has been found.\n",
      "\n",
      "No document including the word retardons has been found.\n",
      "\n",
      "No document including the word reteindre has been found.\n",
      "\n",
      "No document including the word retouchent has been found.\n",
      "\n",
      "No document including the word retransmettant has been found.\n",
      "\n",
      "No document including the word ricanaient has been found.\n",
      "\n",
      "No document including the word ripostaient has been found.\n",
      "\n",
      "No document including the word ronchonnent has been found.\n",
      "\n",
      "No document including the word ronfleurs has been found.\n",
      "\n",
      "No document including the word rotondes has been found.\n",
      "\n",
      "No document including the word rudesses has been found.\n",
      "\n",
      "No document including the word rugissait has been found.\n",
      "\n",
      "No document including the word rutilent has been found.\n",
      "\n",
      "No document including the word réceptionnées has been found.\n",
      "\n",
      "No document including the word réconforts has been found.\n",
      "\n",
      "No document including the word récupéreras has been found.\n",
      "\n",
      "No document including the word rémunéraient has been found.\n",
      "\n",
      "No document including the word réordonner has been found.\n",
      "\n",
      "No document including the word réprimerait has been found.\n",
      "\n",
      "No document including the word rétrécissements has been found.\n",
      "\n",
      "No document including the word réécrivez has been found.\n",
      "\n",
      "No document including the word sarreau has been found.\n",
      "\n",
      "No document including the word sauniers has been found.\n",
      "\n",
      "No document including the word saussaies has been found.\n",
      "\n",
      "No document including the word savonnage has been found.\n",
      "\n",
      "No document including the word secouons has been found.\n",
      "\n",
      "No document including the word secrétairerie has been found.\n",
      "\n",
      "No document including the word serre-livres has been found.\n",
      "\n",
      "No document including the word servomoteur has been found.\n",
      "\n",
      "No document including the word sifflez has been found.\n",
      "\n",
      "No document including the word siliceux has been found.\n",
      "\n",
      "No document including the word snobée has been found.\n",
      "\n",
      "No document including the word soldeurs has been found.\n",
      "\n",
      "No document including the word solidification has been found.\n",
      "\n",
      "No document including the word sombreraient has been found.\n",
      "\n",
      "No document including the word sonomètres has been found.\n",
      "\n",
      "No document including the word soudoyés has been found.\n",
      "\n",
      "No document including the word soufferte has been found.\n",
      "\n",
      "No document including the word soulagez has been found.\n",
      "\n",
      "No document including the word soupait has been found.\n",
      "\n",
      "No document including the word soupesant has been found.\n",
      "\n",
      "No document including the word sous-secrétaires has been found.\n",
      "\n",
      "No document including the word soutirent has been found.\n",
      "\n",
      "No document including the word sphinge has been found.\n",
      "\n",
      "No document including the word sponsorisait has been found.\n",
      "\n",
      "No document including the word statuerait has been found.\n",
      "\n",
      "No document including the word stridentes has been found.\n",
      "\n",
      "No document including the word stérilement has been found.\n",
      "\n",
      "No document including the word suborné has been found.\n",
      "\n",
      "No document including the word succombes has been found.\n",
      "\n",
      "No document including the word suceuses has been found.\n",
      "\n",
      "No document including the word sulfurée has been found.\n",
      "\n",
      "No document including the word suons has been found.\n",
      "\n",
      "No document including the word supposions has been found.\n",
      "\n",
      "No document including the word surcroîts has been found.\n",
      "\n",
      "No document including the word surfactant has been found.\n",
      "\n",
      "No document including the word surjets has been found.\n",
      "\n",
      "No document including the word survinrent has been found.\n",
      "\n",
      "No document including the word sèmerai has been found.\n",
      "\n",
      "No document including the word sèmerait has been found.\n",
      "\n",
      "No document including the word tarderaient has been found.\n",
      "\n",
      "No document including the word tarière has been found.\n",
      "\n",
      "No document including the word tatouent has been found.\n",
      "\n",
      "No document including the word tenaillent has been found.\n",
      "\n",
      "No document including the word termineraient has been found.\n",
      "\n",
      "No document including the word terre-neuvas has been found.\n",
      "\n",
      "No document including the word thallium has been found.\n",
      "\n",
      "No document including the word thymine has been found.\n",
      "\n",
      "No document including the word tintinnabulent has been found.\n",
      "\n",
      "No document including the word titillation has been found.\n",
      "\n",
      "No document including the word tièdement has been found.\n",
      "\n",
      "No document including the word top-modèles has been found.\n",
      "\n",
      "No document including the word totons has been found.\n",
      "\n",
      "No document including the word transférais has been found.\n",
      "\n",
      "No document including the word travailliez has been found.\n",
      "\n",
      "No document including the word traînasser has been found.\n",
      "\n",
      "No document including the word tremolos has been found.\n",
      "\n",
      "No document including the word trémas has been found.\n",
      "\n",
      "No document including the word trémulante has been found.\n",
      "\n",
      "No document including the word tsé-tsé has been found.\n",
      "\n",
      "No document including the word turbulentes has been found.\n",
      "\n",
      "No document including the word tutoies has been found.\n",
      "\n",
      "No document including the word ulcérations has been found.\n",
      "\n",
      "No document including the word ulcérées has been found.\n",
      "\n",
      "No document including the word unifient has been found.\n",
      "\n",
      "No document including the word vagissements has been found.\n",
      "\n",
      "No document including the word valetaille has been found.\n",
      "\n",
      "No document including the word vantardises has been found.\n",
      "\n",
      "No document including the word vibratos has been found.\n",
      "\n",
      "No document including the word vibrions has been found.\n",
      "\n",
      "No document including the word vichysme has been found.\n",
      "\n",
      "No document including the word violez has been found.\n",
      "\n",
      "No document including the word vivifiants has been found.\n",
      "\n",
      "No document including the word volumétrique has been found.\n",
      "\n",
      "No document including the word vomies has been found.\n",
      "\n",
      "No document including the word votèrent has been found.\n",
      "\n",
      "No document including the word vouvoyait has been found.\n",
      "\n",
      "No document including the word wishbone has been found.\n",
      "\n",
      "No document including the word écroulements has been found.\n",
      "\n",
      "No document including the word éduquera has been found.\n",
      "\n",
      "No document including the word électro-encéphalogramme has been found.\n",
      "\n",
      "No document including the word émancipait has been found.\n",
      "\n",
      "No document including the word émergeât has been found.\n",
      "\n",
      "No document including the word énucléation has been found.\n",
      "\n",
      "No document including the word épaulard has been found.\n",
      "\n",
      "No document including the word éperonnée has been found.\n",
      "\n",
      "No document including the word épouseras has been found.\n",
      "\n",
      "No document including the word érotiquement has been found.\n",
      "\n",
      "No document including the word éternisaient has been found.\n",
      "\n",
      "No document including the word éthers has been found.\n",
      "\n",
      "No document including the word étranglais has been found.\n",
      "\n",
      "No document including the word étrangles has been found.\n",
      "\n",
      "No document including the word étranglez has been found.\n",
      "\n",
      "CPU times: user 6h 18min 7s, sys: 10.5 s, total: 6h 18min 17s\n",
      "Wall time: 6h 19min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = {}\n",
    "# counter to keep track of how many example sentences we found\n",
    "i=0\n",
    "\n",
    "for word in common_words.Word.unique():\n",
    "    # retrieve documents (i.e., rows) from the corpus including this word\n",
    "    example_docs = corpus[corpus['Text'].str.contains(word, na=False, case=False)]\n",
    "    if example_docs.shape[0] == 0:\n",
    "        print(\"No document including the word {} has been found.\\n\".format(word))\n",
    "    else:\n",
    "        for index, row in example_docs.iterrows():\n",
    "            # check that the document really includes the word (e.g., 'beau') \n",
    "            # and not a string containing this word (e.g., 'beauté')\n",
    "            if word.lower() in word_tokenize(row['Text'].lower()):\n",
    "                try:\n",
    "                    text = split_text_into_sentences(text=row['Text'],language='fr')\n",
    "                    for sent in text:\n",
    "                        if word in sent:\n",
    "                            # add sentence including the word we're looking for as a key\n",
    "                            i += 1\n",
    "                            data[i] = [word, 'FRA', sent]\n",
    "                except:\n",
    "                    print(\"Something went wrong when splitting the text into sentences.\")\n",
    "\n",
    "\n",
    "# convert dictionary into a pandas dataframe\n",
    "example_sentences = pd.DataFrame.from_dict(data, orient='index', columns=['Word', 'Language', 'Example'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13574, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_sentences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQ0WYsnNBUa1"
   },
   "source": [
    "We notice that quite a few sentences were not parsed successfully. To be honest, I don't know why. However, we still managed to extract 13'574 example sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Language</th>\n",
       "      <th>Example</th>\n",
       "      <th>lemme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandonniez</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Si vous maintenez cette pratique sans faille d...</td>\n",
       "      <td>abandonner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abattirent</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Mais des hommes sont venus, qui firent avec ce...</td>\n",
       "      <td>abattre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abattirent</td>\n",
       "      <td>FRA</td>\n",
       "      <td>A ce spectacle, les chevaliers indignés se ruè...</td>\n",
       "      <td>abattre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abattirent</td>\n",
       "      <td>FRA</td>\n",
       "      <td>« Lui et ses compagnons abattirent une infinit...</td>\n",
       "      <td>abattre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abattis</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Mohamed VI... numérotez vos abattis... votre h...</td>\n",
       "      <td>abattis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word Language                                            Example  \\\n",
       "0  abandonniez      FRA  Si vous maintenez cette pratique sans faille d...   \n",
       "1   abattirent      FRA  Mais des hommes sont venus, qui firent avec ce...   \n",
       "2   abattirent      FRA  A ce spectacle, les chevaliers indignés se ruè...   \n",
       "3   abattirent      FRA  « Lui et ses compagnons abattirent une infinit...   \n",
       "4      abattis      FRA  Mohamed VI... numérotez vos abattis... votre h...   \n",
       "\n",
       "        lemme  \n",
       "0  abandonner  \n",
       "1     abattre  \n",
       "2     abattre  \n",
       "3     abattre  \n",
       "4     abattis  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = pd.merge(example_sentences, lexique383, on='Word', how='inner')\n",
    "final_output.drop(columns=['cgram', 'cgramortho'], inplace=True)\n",
    "final_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/!\\ We added the lemma to facilitate the example sentences import to Kam4D. However, the same costume can come from multiple lemma. The lemma in the CSV file were obtained by merging the <code>example_sentences</code> table with the <code>lexique383</code> one. If multiple lemma were available in lexique383, it automatically picked the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHflDgPsgbRj"
   },
   "outputs": [],
   "source": [
    "# export dataframe as a CSV file\n",
    "final_output.to_csv('/drive/My Drive/example_sentences.csv', index=False, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Example_sentences_drive.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "kamusi2",
   "language": "python",
   "name": "kamusi2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
